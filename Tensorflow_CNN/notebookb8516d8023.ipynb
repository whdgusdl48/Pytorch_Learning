{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (112, 112)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    \n    datasets = ['/kaggle/input/intel-image-classification/seg_train/seg_train', '/kaggle/input/intel-image-classification/seg_test/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_images, train_labels), (test_image, test_labels) = load_data()","execution_count":7,"outputs":[{"output_type":"stream","text":"  1%|          | 22/2191 [00:00<00:09, 219.46it/s]","name":"stderr"},{"output_type":"stream","text":"Loading /kaggle/input/intel-image-classification/seg_train/seg_train\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 2191/2191 [00:06<00:00, 324.15it/s]\n100%|██████████| 2404/2404 [00:08<00:00, 279.81it/s]\n100%|██████████| 2274/2274 [00:08<00:00, 263.69it/s]\n100%|██████████| 2512/2512 [00:08<00:00, 302.95it/s]\n100%|██████████| 2271/2271 [00:08<00:00, 269.98it/s]\n100%|██████████| 2382/2382 [00:08<00:00, 286.66it/s]\n  7%|▋         | 32/437 [00:00<00:01, 315.27it/s]","name":"stderr"},{"output_type":"stream","text":"Loading /kaggle/input/intel-image-classification/seg_test/seg_test\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 437/437 [00:01<00:00, 288.62it/s]\n100%|██████████| 553/553 [00:01<00:00, 293.71it/s]\n100%|██████████| 510/510 [00:01<00:00, 300.79it/s]\n100%|██████████| 525/525 [00:02<00:00, 217.71it/s]\n100%|██████████| 474/474 [00:01<00:00, 282.55it/s]\n100%|██████████| 501/501 [00:01<00:00, 342.03it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import *\nfrom keras.models import Sequential\n\nClassification_Model_Keras = Sequential([\n        Conv2D(256,kernel_size=(3,3),activation='relu',input_shape=(112,112,3)),\n        Conv2D(128,kernel_size=(3,3),activation='relu'),\n        Conv2D(64,kernel_size=(3,3),activation='relu'),\n        MaxPool2D(4,4),\n        Conv2D(128,kernel_size=(3,3),activation='relu'),    \n        Conv2D(64,kernel_size=(3,3),activation='relu'),    \n        Conv2D(32,kernel_size=(3,3),activation='relu'),\n        MaxPool2D(4,4),\n        Flatten() ,    \n        Dense(128,activation='relu') ,    \n        Dense(64,activation='relu') ,    \n        Dense(32,activation='relu') ,        \n        Dropout(rate=0.5) ,            \n        Dense(6,activation='softmax') ,    \n        ])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Model_Keras.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 110, 110, 256)     7168      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 108, 108, 128)     295040    \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 106, 106, 64)      73792     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 26, 26, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 22, 22, 64)        73792     \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 20, 20, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 800)               0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               102528    \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_2 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndropout (Dropout)            (None, 32)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 198       \n=================================================================\nTotal params: 655,174\nTrainable params: 655,174\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Model_Keras.compile(optimizer ='adam',\n                                   loss='sparse_categorical_crossentropy',\n                                   metrics=['accuracy'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 40\nKerasModel = Classification_Model_Keras.fit(train_images, train_labels, epochs=30,batch_size=64,verbose=1)","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n220/220 [==============================] - 30s 137ms/step - loss: 1.7715 - accuracy: 0.2825\nEpoch 2/10\n220/220 [==============================] - 30s 136ms/step - loss: 1.1804 - accuracy: 0.5277\nEpoch 3/10\n220/220 [==============================] - 30s 135ms/step - loss: 1.0206 - accuracy: 0.5976\nEpoch 4/10\n220/220 [==============================] - 30s 136ms/step - loss: 0.9435 - accuracy: 0.6382\nEpoch 5/10\n220/220 [==============================] - 30s 135ms/step - loss: 0.8926 - accuracy: 0.6568\nEpoch 6/10\n220/220 [==============================] - 30s 135ms/step - loss: 0.8439 - accuracy: 0.6895\nEpoch 7/10\n220/220 [==============================] - 30s 135ms/step - loss: 0.8014 - accuracy: 0.7113\nEpoch 8/10\n220/220 [==============================] - 30s 136ms/step - loss: 0.7520 - accuracy: 0.7289\nEpoch 9/10\n220/220 [==============================] - 30s 135ms/step - loss: 0.7214 - accuracy: 0.7483\nEpoch 10/10\n220/220 [==============================] - 30s 136ms/step - loss: 0.6692 - accuracy: 0.7649\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = Classification_Model_Keras.evaluate(test_image,  test_labels, verbose=1)\nprint('\\n테스트 정확도:', test_acc)","execution_count":14,"outputs":[{"output_type":"stream","text":"94/94 [==============================] - 2s 24ms/step - loss: 0.6023 - accuracy: 0.7930\n\n테스트 정확도: 0.7929999828338623\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}